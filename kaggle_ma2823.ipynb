{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing,metrics\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_words_title  Number of words in the article's titles\r\n",
      "nb_words_content  Number of words in the article\r\n",
      "pp_uniq_words  Proportion of unique words in the article\r\n",
      "pp_stop_words  Proportion of stop words (i.e. words predefined to be too common to be of use for interpretation or queries, such as 'the', 'a', 'and', etc.)\r\n",
      "pp_uniq_non-stop_words  Proportion of non-stop words among unique words\r\n",
      "nb_links  Number of hyperlinks in the article\r\n",
      "nb_outside_links  Number of hyperlinks pointing to another website\r\n",
      "nb_images  Number of images in the article\r\n",
      "nb_videos  Number of videos in the article\r\n",
      "ave_word_length  Average word length\r\n",
      "nb_keywords  Number of keywords in the metadata\r\n",
      "category  Category of the article: 0-Lifestyle, 1-Entertainment, 2-Business, 3-Web, 4-Tech, 5-World\r\n",
      "nb_mina_mink  Minimum number of share counts among all articles with at least one keyword in common with the article\r\n",
      "nb_mina_maxk  Minimum number of maximum share counts per keyword\r\n",
      "nb_mina_avek  Minimum number of average share counts per keyword\r\n",
      "nb_maxa_mink  Maximum number of minimum share counts per keyword\r\n",
      "nb_maxa_maxk  Maximum number of share counts among all articles with at least one keyword in common with the article\r\n",
      "nb_maxa_avek  Maximum number of average share counts per keyword\r\n",
      "nb_avea_mink  Average number of minimum share counts per keyword\r\n",
      "nb_avea_maxk  Average number of maximum share counts per keyword\r\n",
      "nb_avea_avek  Average number of average share counts per keyword\r\n",
      "nb_min_linked  Minimum number of shares of articles from the same website linked within the article\r\n",
      "nb_max_linked  Maximum number of shares of articles from the same website linked within the article\r\n",
      "nb_ave_linked  Average number of shares of articles from the same website linked within the article\r\n",
      "weekday  Day of the week: 0-Monday, 1-Tuesday, 2-Wednesday, until 6-Sunday\r\n",
      "dist_topic_0  Distance to topic 0\r\n",
      "dist_topic_1  Distance to topic 1\r\n",
      "dist_topic_2  Distance to topic 2\r\n",
      "dist_topic_3  Distance to topic 3\r\n",
      "dist_topic_4  Distance to topic 4\r\n",
      "subj  Subjectivity\r\n",
      "polar  Sentiment polarity \r\n",
      "pp_pos_words  Proportion of positive words in the article\r\n",
      "pp_neg_words  Proportion of negative words in the article\r\n",
      "pp_pos_words_in_nonneutral  Proportion of positive words among the non-neutral words of the article\r\n",
      "ave_polar_pos  Average sentiment polarity of the positive words\r\n",
      "min_polar_pos  Minimum sentiment polarity of the positive words\r\n",
      "max_polar_pos  Maximum sentiment polarity of the positive words\r\n",
      "ave_polar_neg  Average sentiment polarity of the negative words\r\n",
      "min_polar_neg  Mimimum sentiment polarity of the negative words\r\n",
      "max_polar_neg  Maximum sentiment polarity of the negative words\r\n",
      "subj_title  Subjectivity of the title\r\n",
      "polar_title  Polarity of the title\r\n"
     ]
    }
   ],
   "source": [
    "#descriptions of features\n",
    "!cat data/kaggle_data/features.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XQ/envs/scipy35/lib/python3.5/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_words_title</th>\n",
       "      <th>nb_words_content</th>\n",
       "      <th>pp_uniq_words</th>\n",
       "      <th>pp_stop_words</th>\n",
       "      <th>pp_uniq_non-stop_words</th>\n",
       "      <th>nb_links</th>\n",
       "      <th>nb_outside_links</th>\n",
       "      <th>nb_images</th>\n",
       "      <th>nb_videos</th>\n",
       "      <th>ave_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>pp_neg_words</th>\n",
       "      <th>pp_pos_words_in_nonneutral</th>\n",
       "      <th>ave_polar_pos</th>\n",
       "      <th>min_polar_pos</th>\n",
       "      <th>max_polar_pos</th>\n",
       "      <th>ave_polar_neg</th>\n",
       "      <th>min_polar_neg</th>\n",
       "      <th>max_polar_neg</th>\n",
       "      <th>subj_title</th>\n",
       "      <th>polar_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>258</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>6.897000e-09</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01653</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2344</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>263</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>6.623000e-09</td>\n",
       "      <td>0.8543</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04701</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2170</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>1.422000e-09</td>\n",
       "      <td>0.5903</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01512</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3585</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2403</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>107</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>1.538000e-08</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02151</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.28570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_words_title  nb_words_content  pp_uniq_words  pp_stop_words  \\\n",
       "0              12               258         0.5745   6.897000e-09   \n",
       "1               8                11         0.0000   1.000000e+00   \n",
       "2              10               263         0.7249   6.623000e-09   \n",
       "3              13              1281         0.4067   1.422000e-09   \n",
       "4               9               107         0.8152   1.538000e-08   \n",
       "\n",
       "   pp_uniq_non-stop_words  nb_links  nb_outside_links  nb_images  nb_videos  \\\n",
       "0                  0.6897       4.0                 2          0          0   \n",
       "1                  0.0000       0.0                 0          0          0   \n",
       "2                  0.8543       6.0                 3          2          0   \n",
       "3                  0.5903      29.0                 4          1          1   \n",
       "4                  0.8154       5.0                 2          0          0   \n",
       "\n",
       "   ave_word_length     ...       pp_neg_words  pp_pos_words_in_nonneutral  \\\n",
       "0                4     ...            0.01653                      0.7143   \n",
       "1                0     ...            0.00000                      0.0000   \n",
       "2                5     ...            0.04701                      0.5000   \n",
       "3                4     ...            0.01512                      0.7500   \n",
       "4                4     ...            0.02151                      0.6667   \n",
       "\n",
       "   ave_polar_pos  min_polar_pos  max_polar_pos  ave_polar_neg  min_polar_neg  \\\n",
       "0         0.2967        0.10000            1.0        -0.2344           -0.3   \n",
       "1         0.0000        0.00000            0.0         0.0000            0.0   \n",
       "2         0.2617        0.10000            1.0        -0.2170           -0.5   \n",
       "3         0.3585        0.03333            1.0        -0.2403           -0.5   \n",
       "4         0.4881        0.28570            1.0        -0.8000           -1.0   \n",
       "\n",
       "   max_polar_neg  subj_title  polar_title  \n",
       "0        -0.1875       0.125          0.0  \n",
       "1         0.0000       0.525          0.3  \n",
       "2        -0.1250       0.000         -0.2  \n",
       "3        -0.0500       0.000          0.0  \n",
       "4        -0.6000       0.000          0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data = pd.read_csv('data/kaggle_data/features.txt', header=None, sep=\"  \", names=['feature_names', 'feature_description'])\n",
    "target_data = pd.read_csv('data/kaggle_data/train-targets.csv', sep=\",\")\n",
    "target_data.head(5)\n",
    "y_tr = target_data['Prediction'].values\n",
    "list_feature_names = list(feature_data['feature_names'])\n",
    "train_data = pd.read_csv('data/kaggle_data/train.csv', header=None, sep=\" \", names=list_feature_names)\n",
    "train_data.head(5)\n",
    "test_data = pd.read_csv('data/kaggle_data/test-val.csv', header=None, sep=\" \", names=list_feature_names)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Binarizing weekday data into working/non-working days 0-4 weekdays, 5 or 6 weekends\n",
    "def binarize_weekends(dataframe):\n",
    "    days = list(dataframe['weekday'])\n",
    "    is_weekend = [0 if day in [0,1,2,3,4] else 1 for day in days]\n",
    "    dataframe['weekday']=is_weekend\n",
    "    return dataframe\n",
    "\n",
    "#removing strongly correlated features, i.e. pp_uniq_words'<-> 'pp_uniq_non-stop_words'), ('nb_links'<-> 'nb_outside_links'), ('nb_mina_maxk'<-> 'nb_mina_avek')\n",
    "#dropped_col_list=['pp_uniq_non-stop_words','nb_outside_links','nb_mina_avek']\n",
    "dropped_col_list=[]\n",
    "\n",
    "train_data = binarize_weekends(train_data)\n",
    "test_data = binarize_weekends(test_data)\n",
    "train_data = train_data.drop(dropped_col_list,axis=1)\n",
    "test_data = test_data.drop(dropped_col_list,axis=1)\n",
    "#print(test_data['weekday'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the weekday data and encode it using a dummy categorical encoding\n",
    "\"\"\"\n",
    "weekday_data = pd.get_dummies(train_data['weekday'], prefix='weekday', drop_first=True)\n",
    "other_data = train_data.drop(['weekday'], axis=1)\n",
    "train_data = pd.concat([weekday_data, other_data], axis=1)\n",
    "\n",
    "weekday_data = pd.get_dummies(test_data['weekday'], prefix='weekday', drop_first=True)\n",
    "other_data = test_data.drop(['weekday'], axis=1)\n",
    "test_data = pd.concat([weekday_data, other_data], axis=1)\n",
    "\n",
    "\"\"\"\n",
    "category_data = pd.get_dummies(train_data['category'], prefix='cat', drop_first=True)\n",
    "other_data = train_data.drop(['category'], axis=1)\n",
    "train_data = pd.concat([category_data, other_data], axis=1)\n",
    "\n",
    "\n",
    "category_data = pd.get_dummies(test_data['category'], prefix='cat', drop_first=True)\n",
    "other_data = test_data.drop(['category'], axis=1)\n",
    "test_data = pd.concat([category_data, other_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>cat_4</th>\n",
       "      <th>cat_5</th>\n",
       "      <th>nb_words_title</th>\n",
       "      <th>nb_words_content</th>\n",
       "      <th>pp_uniq_words</th>\n",
       "      <th>pp_stop_words</th>\n",
       "      <th>pp_uniq_non-stop_words</th>\n",
       "      <th>...</th>\n",
       "      <th>pp_neg_words</th>\n",
       "      <th>pp_pos_words_in_nonneutral</th>\n",
       "      <th>ave_polar_pos</th>\n",
       "      <th>min_polar_pos</th>\n",
       "      <th>max_polar_pos</th>\n",
       "      <th>ave_polar_neg</th>\n",
       "      <th>min_polar_neg</th>\n",
       "      <th>max_polar_neg</th>\n",
       "      <th>subj_title</th>\n",
       "      <th>polar_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>843</td>\n",
       "      <td>0.5358</td>\n",
       "      <td>2.092000e-09</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.3160</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>805</td>\n",
       "      <td>0.4196</td>\n",
       "      <td>2.165000e-09</td>\n",
       "      <td>0.5693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.3081</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.3463</td>\n",
       "      <td>-0.7143</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>145</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>1.163000e-08</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>201</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>9.259000e-09</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>673</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>2.500000e-09</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2435</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat_1  cat_2  cat_3  cat_4  cat_5  nb_words_title  nb_words_content  \\\n",
       "2000      1      0      0      0      0               9               843   \n",
       "2001      0      0      0      0      1               9               805   \n",
       "2002      0      0      0      1      0               8               145   \n",
       "2003      0      0      0      1      0              12               201   \n",
       "2004      0      0      0      0      1              13               673   \n",
       "\n",
       "      pp_uniq_words  pp_stop_words  pp_uniq_non-stop_words     ...       \\\n",
       "2000         0.5358   2.092000e-09                  0.7469     ...        \n",
       "2001         0.4196   2.165000e-09                  0.5693     ...        \n",
       "2002         0.7594   1.163000e-08                  0.8488     ...        \n",
       "2003         0.6359   9.259000e-09                  0.8148     ...        \n",
       "2004         0.4609   2.500000e-09                  0.5950     ...        \n",
       "\n",
       "      pp_neg_words  pp_pos_words_in_nonneutral  ave_polar_pos  min_polar_pos  \\\n",
       "2000      0.019230                      0.7143         0.4437        0.03333   \n",
       "2001      0.025710                      0.5349         0.3081        0.05000   \n",
       "2002      0.007519                      0.8333         0.3673        0.13640   \n",
       "2003      0.027030                      0.7368         0.3721        0.13640   \n",
       "2004      0.021440                      0.5625         0.3500        0.05000   \n",
       "\n",
       "      max_polar_pos  ave_polar_neg  min_polar_neg  max_polar_neg  subj_title  \\\n",
       "2000            1.0        -0.3160        -0.8000          -0.05         0.0   \n",
       "2001            0.8        -0.3463        -0.7143          -0.10         0.9   \n",
       "2002            0.5        -0.2000        -0.2000          -0.20         0.0   \n",
       "2003            0.6        -0.4000        -0.4000          -0.40         0.0   \n",
       "2004            0.6        -0.2435        -0.8000          -0.10         0.0   \n",
       "\n",
       "      polar_title  \n",
       "2000          0.0  \n",
       "2001          0.3  \n",
       "2002          0.0  \n",
       "2003          0.0  \n",
       "2004          0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation procedure, with standardization\n",
    "def cross_validate_regr_with_scaling(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions. \n",
    "    Use a scaler to scale the features to mean 0, standard deviation 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  Regressor instance; must have the following methods:\n",
    "        - fit(X, y) to train the regressor on the data X, y\n",
    "        - predict_proba(X) to apply the trained regressor to the data X and return predicted values\n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.zeros(labels.shape)\n",
    "    pca = decomposition.PCA(n_components=30)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    pca.fit(design_matrix)\n",
    "    for tr, te in cv_folds:\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        Xtr = pca.transform(Xtr)\n",
    "        ytr =  labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        Xte = pca.transform(Xte)\n",
    "        regressor.fit(Xtr, ytr)\n",
    "        pred[te] = (regressor.predict(Xte))    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XQ/envs/scipy35/lib/python3.5/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "#create folds\n",
    "from sklearn import cross_validation\n",
    "\n",
    "X_tr = train_data.values\n",
    "X_te = test_data.values\n",
    "print(X_tr.shape)\n",
    "folds_regr = cross_validation.StratifiedKFold(y_tr,n_folds=10,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with standardization; RMSE:  1.05745766251 ; alpha:  100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import linear_model\n",
    "param_grid = {'alpha': np.logspace(-2, 4, 10)}\n",
    "\"\"\"\n",
    "regr_lasso_stand = linear_model.LinearRegression(fit_intercept=True)\n",
    "ypred_lasso_stand = cross_validate_regr_with_scaling(X_tr, y_tr, regr_lasso_stand, folds_regr)\n",
    "ypred_lasso_stand = np.where(ypred_lasso_stand>0,ypred_lasso_stand,0)\n",
    "print(metrics.mean_squared_log_error(y_tr,ypred_lasso_stand))\n",
    "#print(regr_lasso_stand.predict(X_te))\n",
    "#print(\"with standardization; RMSE: \", np.sqrt(metrics.mean_squared_error(y_te,\n",
    "#                                                                      ypred_lasso_stand)))\n",
    "\n",
    "np.random.seed(5)\n",
    "regr_ridge_stand_opt = GridSearchCV(linear_model.Ridge(), param_grid, scoring='neg_mean_squared_error')\n",
    "ypred_ridge_stand_opt = cross_validate_regr_with_scaling(X_tr,y_tr,regr_ridge_stand_opt,folds_regr)\n",
    "ypred_ridge_stand_opt = np.where(ypred_ridge_stand_opt>0,ypred_ridge_stand_opt,0)\n",
    "print(\"with scaling:\", metrics.mean_squared_log_error(y_tr,ypred_ridge_stand_opt), 'alpha: ', regr_lasso_stand_opt.best_params_['alpha'])\n",
    "\"\"\"\n",
    "np.random.seed(5)\n",
    "regr_lasso_stand_opt = GridSearchCV(linear_model.Lasso(), param_grid,scoring='neg_mean_squared_error')\n",
    "ypred_lasso_stand_opt = cross_validate_regr_with_scaling(X_tr, y_tr, regr_lasso_stand_opt, folds_regr)\n",
    "ypred_lasso_stand_opt = np.where(ypred_lasso_stand_opt>0,ypred_lasso_stand_opt,0)\n",
    "print(\"with standardization; RMSE: \", np.sqrt(metrics.mean_squared_log_error(y_tr,\n",
    "                                                                       ypred_lasso_stand_opt)),'; alpha: ', regr_lasso_stand_opt.best_params_['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=52 must be between 0 and n_features=47 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c013f92e7126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_projected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/scipy35/lib/python3.5/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \"\"\"\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/scipy35/lib/python3.5/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/scipy35/lib/python3.5/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[1;32m    405\u001b[0m                              \u001b[0;34m\"n_features=%r with svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                              % (n_components, n_features))\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Center data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=52 must be between 0 and n_features=47 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X_tr)\n",
    "X_scaled = std_scale.transform(X_tr)\n",
    "\n",
    "pca = decomposition.PCA(n_components=52)\n",
    "pca.fit(X_scaled)\n",
    "X_projected = pca.transform(X_scaled)\n",
    "print(pca.explained_variance_ratio_)\n",
    "plt.bar(np.arange(52), pca.explained_variance_ratio_, color='blue')\n",
    "plt.xlim([-1, 52])\n",
    "plt.xlabel(\"Number of PCs\", fontsize=16)\n",
    "plt.ylabel(\"Fraction of variance explained\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(ypred_lasso_stand_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(max(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=30)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pca.fit(X_tr)\n",
    "pred = regr_lasso_stand_opt.predict(pca.transform(scaler.fit_transform(X_te)))\n",
    "print(pred.shape)\n",
    "pred_int = list(map(int, np.where(pred>0,pred,0)))\n",
    "print(max(np.array(pred_int)))\n",
    "print(min(np.array(pred_int)))\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df['Prediction'] = pred_int\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': range(1, 40, 2)}\n",
      "{'n_neighbors': 39}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn import neighbors\n",
    "from sklearn import model_selection\n",
    "\n",
    "#each classis defined as the multiples of 100\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 100.0)) * 100\n",
    "\n",
    "def classify_labels(labels):\n",
    "    return [roundup(x)/100 for x in labels]\n",
    "    \n",
    "#y_tr = classify_labels(y_tr)\n",
    "\n",
    "#making knn predictions\n",
    "classifier = neighbors.KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors':range(1,40,2) }\n",
    "print(param_grid)\n",
    "clf_knn_opt = model_selection.GridSearchCV(classifier,  param_grid=param_grid, cv=folds_regr)\n",
    "clf_knn_opt.fit(X_tr,y_tr)\n",
    "print(clf_knn_opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (560,) could not be broadcast to indexing result of shape (560,1111)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-22b7a4fc65a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mypred_clf_knn_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_knn_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolds_regr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred_clf_knn_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_log_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred_clf_knn_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-22b7a4fc65a6>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(design_matrix, labels, regressor, cv_folds)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mXte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#regressor.fit(Xtr, ytr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (560,) could not be broadcast to indexing result of shape (560,1111)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def cross_validate(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions. \n",
    "    Use a scaler to scale the features to mean 0, standard deviation 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  Regressor instance; must have the following methods:\n",
    "        - fit(X, y) to train the regressor on the data X, y\n",
    "        - predict_proba(X) to apply the trained regressor to the data X and return predicted values\n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    #labels = np.array(labels)\n",
    "    n_classes = len(clf_knn_opt.classes_)\n",
    "    pred = np.zeros((labels.shape[0],n_classes))\n",
    "    print(n_classes)\n",
    "    for tr, te in cv_folds:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        ytr =  labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        #regressor.fit(Xtr, ytr)\n",
    "        pred[te, :] = regressor.predict(Xte)\n",
    "    return pred\n",
    "\n",
    "\n",
    "ypred_clf_knn_opt = cross_validate(X_tr,y_tr,clf_knn_opt.best_estimator_,folds_regr)\n",
    "print(ypred_clf_knn_opt.shape)\n",
    "print(metrics.mean_squared_log_error(y_tr,ypred_clf_knn_opt))\n",
    "\"\"\"\n",
    "fpr_clf_knn_opt, tpr_clf_knn_opt, thresh = metrics.roc_curve(y_tr,ypred_clf_knn_opt)\n",
    "knn_h,        = plt.plot(fpr_clf_knn_opt, tpr_clf_knn_opt, 'r-')\n",
    "knn_auc       = metrics.auc(fpr_clf_knn_opt, tpr_clf_knn_opt)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "test=clf_knn_opt.predict(X_tr)\n",
    "print(len(clf_knn_opt.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
