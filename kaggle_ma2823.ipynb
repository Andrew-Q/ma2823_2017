{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing,metrics\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_words_title  Number of words in the article's titles\r\n",
      "nb_words_content  Number of words in the article\r\n",
      "pp_uniq_words  Proportion of unique words in the article\r\n",
      "pp_stop_words  Proportion of stop words (i.e. words predefined to be too common to be of use for interpretation or queries, such as 'the', 'a', 'and', etc.)\r\n",
      "pp_uniq_non-stop_words  Proportion of non-stop words among unique words\r\n",
      "nb_links  Number of hyperlinks in the article\r\n",
      "nb_outside_links  Number of hyperlinks pointing to another website\r\n",
      "nb_images  Number of images in the article\r\n",
      "nb_videos  Number of videos in the article\r\n",
      "ave_word_length  Average word length\r\n",
      "nb_keywords  Number of keywords in the metadata\r\n",
      "category  Category of the article: 0-Lifestyle, 1-Entertainment, 2-Business, 3-Web, 4-Tech, 5-World\r\n",
      "nb_mina_mink  Minimum number of share counts among all articles with at least one keyword in common with the article\r\n",
      "nb_mina_maxk  Minimum number of maximum share counts per keyword\r\n",
      "nb_mina_avek  Minimum number of average share counts per keyword\r\n",
      "nb_maxa_mink  Maximum number of minimum share counts per keyword\r\n",
      "nb_maxa_maxk  Maximum number of share counts among all articles with at least one keyword in common with the article\r\n",
      "nb_maxa_avek  Maximum number of average share counts per keyword\r\n",
      "nb_avea_mink  Average number of minimum share counts per keyword\r\n",
      "nb_avea_maxk  Average number of maximum share counts per keyword\r\n",
      "nb_avea_avek  Average number of average share counts per keyword\r\n",
      "nb_min_linked  Minimum number of shares of articles from the same website linked within the article\r\n",
      "nb_max_linked  Maximum number of shares of articles from the same website linked within the article\r\n",
      "nb_ave_linked  Average number of shares of articles from the same website linked within the article\r\n",
      "weekday  Day of the week: 0-Monday, 1-Tuesday, 2-Wednesday, until 6-Sunday\r\n",
      "dist_topic_0  Distance to topic 0\r\n",
      "dist_topic_1  Distance to topic 1\r\n",
      "dist_topic_2  Distance to topic 2\r\n",
      "dist_topic_3  Distance to topic 3\r\n",
      "dist_topic_4  Distance to topic 4\r\n",
      "subj  Subjectivity\r\n",
      "polar  Sentiment polarity \r\n",
      "pp_pos_words  Proportion of positive words in the article\r\n",
      "pp_neg_words  Proportion of negative words in the article\r\n",
      "pp_pos_words_in_nonneutral  Proportion of positive words among the non-neutral words of the article\r\n",
      "ave_polar_pos  Average sentiment polarity of the positive words\r\n",
      "min_polar_pos  Minimum sentiment polarity of the positive words\r\n",
      "max_polar_pos  Maximum sentiment polarity of the positive words\r\n",
      "ave_polar_neg  Average sentiment polarity of the negative words\r\n",
      "min_polar_neg  Mimimum sentiment polarity of the negative words\r\n",
      "max_polar_neg  Maximum sentiment polarity of the negative words\r\n",
      "subj_title  Subjectivity of the title\r\n",
      "polar_title  Polarity of the title\r\n"
     ]
    }
   ],
   "source": [
    "#descriptions of features\n",
    "!cat data/kaggle_data/features.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XQ/envs/scipy35/lib/python3.5/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_words_title</th>\n",
       "      <th>nb_words_content</th>\n",
       "      <th>pp_uniq_words</th>\n",
       "      <th>pp_stop_words</th>\n",
       "      <th>pp_uniq_non-stop_words</th>\n",
       "      <th>nb_links</th>\n",
       "      <th>nb_outside_links</th>\n",
       "      <th>nb_images</th>\n",
       "      <th>nb_videos</th>\n",
       "      <th>ave_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>pp_neg_words</th>\n",
       "      <th>pp_pos_words_in_nonneutral</th>\n",
       "      <th>ave_polar_pos</th>\n",
       "      <th>min_polar_pos</th>\n",
       "      <th>max_polar_pos</th>\n",
       "      <th>ave_polar_neg</th>\n",
       "      <th>min_polar_neg</th>\n",
       "      <th>max_polar_neg</th>\n",
       "      <th>subj_title</th>\n",
       "      <th>polar_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>258</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>6.897000e-09</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01653</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2344</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>263</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>6.623000e-09</td>\n",
       "      <td>0.8543</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04701</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2170</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1281</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>1.422000e-09</td>\n",
       "      <td>0.5903</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01512</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.3585</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2403</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>107</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>1.538000e-08</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02151</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>0.28570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_words_title  nb_words_content  pp_uniq_words  pp_stop_words  \\\n",
       "0              12               258         0.5745   6.897000e-09   \n",
       "1               8                11         0.0000   1.000000e+00   \n",
       "2              10               263         0.7249   6.623000e-09   \n",
       "3              13              1281         0.4067   1.422000e-09   \n",
       "4               9               107         0.8152   1.538000e-08   \n",
       "\n",
       "   pp_uniq_non-stop_words  nb_links  nb_outside_links  nb_images  nb_videos  \\\n",
       "0                  0.6897       4.0                 2          0          0   \n",
       "1                  0.0000       0.0                 0          0          0   \n",
       "2                  0.8543       6.0                 3          2          0   \n",
       "3                  0.5903      29.0                 4          1          1   \n",
       "4                  0.8154       5.0                 2          0          0   \n",
       "\n",
       "   ave_word_length     ...       pp_neg_words  pp_pos_words_in_nonneutral  \\\n",
       "0                4     ...            0.01653                      0.7143   \n",
       "1                0     ...            0.00000                      0.0000   \n",
       "2                5     ...            0.04701                      0.5000   \n",
       "3                4     ...            0.01512                      0.7500   \n",
       "4                4     ...            0.02151                      0.6667   \n",
       "\n",
       "   ave_polar_pos  min_polar_pos  max_polar_pos  ave_polar_neg  min_polar_neg  \\\n",
       "0         0.2967        0.10000            1.0        -0.2344           -0.3   \n",
       "1         0.0000        0.00000            0.0         0.0000            0.0   \n",
       "2         0.2617        0.10000            1.0        -0.2170           -0.5   \n",
       "3         0.3585        0.03333            1.0        -0.2403           -0.5   \n",
       "4         0.4881        0.28570            1.0        -0.8000           -1.0   \n",
       "\n",
       "   max_polar_neg  subj_title  polar_title  \n",
       "0        -0.1875       0.125          0.0  \n",
       "1         0.0000       0.525          0.3  \n",
       "2        -0.1250       0.000         -0.2  \n",
       "3        -0.0500       0.000          0.0  \n",
       "4        -0.6000       0.000          0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data = pd.read_csv('data/kaggle_data/features.txt', header=None, sep=\"  \", names=['feature_names', 'feature_description'])\n",
    "target_data = pd.read_csv('data/kaggle_data/train-targets.csv', sep=\",\")\n",
    "target_data.head(5)\n",
    "y_tr = target_data['Prediction'].values\n",
    "list_feature_names = list(feature_data['feature_names'])\n",
    "train_data = pd.read_csv('data/kaggle_data/train.csv', header=None, sep=\" \", names=list_feature_names)\n",
    "train_data.head(5)\n",
    "test_data = pd.read_csv('data/kaggle_data/test-val.csv', header=None, sep=\" \", names=list_feature_names)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform labels to log space\n",
    "def label_transform(k,b,labels):\n",
    "    return np.log(k*labels+b)\n",
    "\n",
    "#transforms logspace predictions back to linear space\n",
    "def inv_label_transform(k,b,log_pred):\n",
    "    return (np.exp(log_pred)-b)/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature engineering and label engineering\n",
    "\n",
    "import math\n",
    "#Binarizing weekday data into working/non-working days 0-4 weekdays, 5 or 6 weekends\n",
    "def binarize_weekends(dataframe):\n",
    "    days = list(dataframe['weekday'])\n",
    "    is_weekend = [0 if day in [0,1,2,3,4] else 1 for day in days]\n",
    "    dataframe['weekday']=is_weekend\n",
    "    return dataframe\n",
    "\n",
    "#doing a continuous sine transfrm on the periodic weekday data\n",
    "def transform_weekdays(dataframe):\n",
    "    days = list(dataframe['weekday'])\n",
    "    cont_days = [math.sin(2*day*math.pi/7) for day in days]\n",
    "    print(cont_days)\n",
    "    dataframe['weekday']=cont_days\n",
    "    return dataframe\n",
    "\n",
    "#removing strongly correlated features, i.e. pp_uniq_words'<-> 'pp_uniq_non-stop_words'), ('nb_links'<-> 'nb_outside_links'), ('nb_mina_maxk'<-> 'nb_mina_avek')\n",
    "dropped_col_list=['pp_uniq_non-stop_words','nb_outside_links','nb_mina_avek']\n",
    "#dropped_col_list=[]\n",
    "b=0\n",
    "k=100\n",
    "y_tr = target_data['Prediction'].values\n",
    "y_tr = label_transform(k,b,y_tr)\n",
    "train_data = binarize_weekends(train_data)\n",
    "test_data = binarize_weekends(test_data)\n",
    "#train_data = transform_weekdays(train_data)\n",
    "#test_data = transform_weekdays(test_data)\n",
    "train_data = train_data.drop(dropped_col_list,axis=1)\n",
    "test_data = test_data.drop(dropped_col_list,axis=1)\n",
    "#print(test_data['weekday'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the weekday data and encode it using a dummy categorical encoding\n",
    "\"\"\"\n",
    "weekday_data = pd.get_dummies(train_data['weekday'], prefix='weekday', drop_first=True)\n",
    "other_data = train_data.drop(['weekday'], axis=1)\n",
    "train_data = pd.concat([weekday_data, other_data], axis=1)\n",
    "\n",
    "weekday_data = pd.get_dummies(test_data['weekday'], prefix='weekday', drop_first=True)\n",
    "other_data = test_data.drop(['weekday'], axis=1)\n",
    "test_data = pd.concat([weekday_data, other_data], axis=1)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "category_data = pd.get_dummies(train_data['category'], prefix='cat', drop_first=True)\n",
    "other_data = train_data.drop(['category'], axis=1)\n",
    "train_data = pd.concat([category_data, other_data], axis=1)\n",
    "\n",
    "\n",
    "category_data = pd.get_dummies(test_data['category'], prefix='cat', drop_first=True)\n",
    "other_data = test_data.drop(['category'], axis=1)\n",
    "test_data = pd.concat([category_data, other_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>cat_4</th>\n",
       "      <th>cat_5</th>\n",
       "      <th>nb_words_title</th>\n",
       "      <th>nb_words_content</th>\n",
       "      <th>pp_uniq_words</th>\n",
       "      <th>pp_stop_words</th>\n",
       "      <th>pp_uniq_non-stop_words</th>\n",
       "      <th>...</th>\n",
       "      <th>pp_neg_words</th>\n",
       "      <th>pp_pos_words_in_nonneutral</th>\n",
       "      <th>ave_polar_pos</th>\n",
       "      <th>min_polar_pos</th>\n",
       "      <th>max_polar_pos</th>\n",
       "      <th>ave_polar_neg</th>\n",
       "      <th>min_polar_neg</th>\n",
       "      <th>max_polar_neg</th>\n",
       "      <th>subj_title</th>\n",
       "      <th>polar_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>843</td>\n",
       "      <td>0.5358</td>\n",
       "      <td>2.092000e-09</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.3160</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>805</td>\n",
       "      <td>0.4196</td>\n",
       "      <td>2.165000e-09</td>\n",
       "      <td>0.5693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.3081</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.3463</td>\n",
       "      <td>-0.7143</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>145</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>1.163000e-08</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.3673</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>201</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>9.259000e-09</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.4000</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>673</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>2.500000e-09</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2435</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat_1  cat_2  cat_3  cat_4  cat_5  nb_words_title  nb_words_content  \\\n",
       "2000      1      0      0      0      0               9               843   \n",
       "2001      0      0      0      0      1               9               805   \n",
       "2002      0      0      0      1      0               8               145   \n",
       "2003      0      0      0      1      0              12               201   \n",
       "2004      0      0      0      0      1              13               673   \n",
       "\n",
       "      pp_uniq_words  pp_stop_words  pp_uniq_non-stop_words     ...       \\\n",
       "2000         0.5358   2.092000e-09                  0.7469     ...        \n",
       "2001         0.4196   2.165000e-09                  0.5693     ...        \n",
       "2002         0.7594   1.163000e-08                  0.8488     ...        \n",
       "2003         0.6359   9.259000e-09                  0.8148     ...        \n",
       "2004         0.4609   2.500000e-09                  0.5950     ...        \n",
       "\n",
       "      pp_neg_words  pp_pos_words_in_nonneutral  ave_polar_pos  min_polar_pos  \\\n",
       "2000      0.019230                      0.7143         0.4437        0.03333   \n",
       "2001      0.025710                      0.5349         0.3081        0.05000   \n",
       "2002      0.007519                      0.8333         0.3673        0.13640   \n",
       "2003      0.027030                      0.7368         0.3721        0.13640   \n",
       "2004      0.021440                      0.5625         0.3500        0.05000   \n",
       "\n",
       "      max_polar_pos  ave_polar_neg  min_polar_neg  max_polar_neg  subj_title  \\\n",
       "2000            1.0        -0.3160        -0.8000          -0.05         0.0   \n",
       "2001            0.8        -0.3463        -0.7143          -0.10         0.9   \n",
       "2002            0.5        -0.2000        -0.2000          -0.20         0.0   \n",
       "2003            0.6        -0.4000        -0.4000          -0.40         0.0   \n",
       "2004            0.6        -0.2435        -0.8000          -0.10         0.0   \n",
       "\n",
       "      polar_title  \n",
       "2000          0.0  \n",
       "2001          0.3  \n",
       "2002          0.0  \n",
       "2003          0.0  \n",
       "2004          0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation procedure, with standardization\n",
    "def cross_validate_regr_with_scaling(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions. \n",
    "    Use a scaler to scale the features to mean 0, standard deviation 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  Regressor instance; must have the following methods:\n",
    "        - fit(X, y) to train the regressor on the data X, y\n",
    "        - predict_proba(X) to apply the trained regressor to the data X and return predicted values\n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.zeros(labels.shape)\n",
    "    pca = decomposition.PCA(n_components=30)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    pca.fit(design_matrix)\n",
    "    for tr, te in cv_folds:\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        Xtr = pca.transform(Xtr)\n",
    "        ytr = labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        Xte = pca.transform(Xte)\n",
    "        regressor.fit(Xtr, ytr)\n",
    "        pred[te] = regressor.predict(Xte)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XQ/envs/scipy35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/XQ/envs/scipy35/lib/python3.5/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 43)\n"
     ]
    }
   ],
   "source": [
    "#create folds\n",
    "from sklearn import cross_validation\n",
    "\n",
    "X_tr = train_data.values\n",
    "X_te = test_data.values\n",
    "print(X_te.shape)\n",
    "folds_regr = cross_validation.StratifiedKFold(y_tr,n_folds=5,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with standardization; RMSLE:  0.86757293221 ; alpha:  0.00483293023857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import linear_model\n",
    "param_grid = {'alpha': np.logspace(-4, 4, 20)}\n",
    "\"\"\"\n",
    "regr_lasso_stand = linear_model.LinearRegression(fit_intercept=True)\n",
    "ypred_lasso_stand = cross_validate_regr_with_scaling(X_tr, y_tr, regr_lasso_stand, folds_regr)\n",
    "ypred_lasso_stand = np.where(ypred_lasso_stand>0,ypred_lasso_stand,0)\n",
    "print(metrics.mean_squared_log_error(y_tr,ypred_lasso_stand))\n",
    "#print(regr_lasso_stand.predict(X_te))\n",
    "#print(\"with standardization; RMSE: \", np.sqrt(metrics.mean_squared_error(y_te,\n",
    "#                                                                      ypred_lasso_stand)))\n",
    "\n",
    "np.random.seed(5)\n",
    "regr_ridge_stand_opt = GridSearchCV(linear_model.Ridge(), param_grid, scoring='neg_mean_squared_error')\n",
    "ypred_ridge_stand_opt = cross_validate_regr_with_scaling(X_tr,y_tr,regr_ridge_stand_opt,folds_regr)\n",
    "ypred_ridge_stand_opt = np.where(ypred_ridge_stand_opt>0,ypred_ridge_stand_opt,0)\n",
    "print(\"with scaling:\", metrics.mean_squared_log_error(y_tr,ypred_ridge_stand_opt), 'alpha: ', regr_lasso_stand_opt.best_params_['alpha'])\n",
    "\"\"\"\n",
    "blist = [-200,-100,100,200,300,400]\n",
    "\n",
    "np.random.seed(5)\n",
    "regr_lasso_stand_opt = GridSearchCV(linear_model.Lasso(), param_grid,scoring='neg_mean_squared_log_error')\n",
    "ypred_lasso_stand_opt_raw = cross_validate_regr_with_scaling(X_tr, y_tr, regr_lasso_stand_opt, folds_regr)\n",
    "#ypred_lasso_stand_opt = np.where(ypred_lasso_stand_opt_raw>0,ypred_lasso_stand_opt_raw,0)\n",
    "print(\"with standardization; RMSLE: \", np.sqrt(metrics.mean_squared_log_error(inv_label_transform(k,b,y_tr),\n",
    "                                                                       inv_label_transform(k,b,ypred_lasso_stand_opt_raw))),'; alpha: ', regr_lasso_stand_opt.best_params_['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1424.09713234  1327.00544761  1890.59455232  1686.37122039  1387.28238089\n",
      "  2225.49069067  1099.32947858  1122.14302025  2318.21518026  2644.29890163]\n",
      "348396.182252\n"
     ]
    }
   ],
   "source": [
    "ypred_lasso_stand_opt=inv_label_transform(k,b,ypred_lasso_stand_opt_raw)\n",
    "print(ypred_lasso_stand_opt[:10])\n",
    "print(max(ypred_lasso_stand_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13192113  0.08634351  0.06351996  0.06338384  0.05522427  0.05246681\n",
      "  0.04845902  0.04579258  0.0422531   0.03488187  0.03015276  0.02816987\n",
      "  0.02731671  0.02344791  0.02288483  0.02207631  0.02088923  0.01906112\n",
      "  0.01847821  0.01638283  0.01568692  0.01400303  0.01327824  0.01208997\n",
      "  0.01130565  0.01095617  0.00951491  0.00890497  0.00731478  0.0066364 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10ec858d0>"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJlZw5xMzMysYU4mZmbWsP8DxglpVVPE/oUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ec6bb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X_tr)\n",
    "X_scaled = std_scale.transform(X_tr)\n",
    "\n",
    "n_pcs = 30\n",
    "\n",
    "pca = decomposition.PCA(n_components=n_pcs)\n",
    "pca.fit(X_scaled)\n",
    "X_projected = pca.transform(X_scaled)\n",
    "print(pca.explained_variance_ratio_)\n",
    "plt.bar(np.arange(n_pcs), pca.explained_variance_ratio_, color='blue')\n",
    "plt.xlim([-1, n_pcs])\n",
    "plt.xlabel(\"Number of PCs\", fontsize=16)\n",
    "plt.ylabel(\"Fraction of variance explained\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(max(ypred_lasso_stand_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(max(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "120470\n",
      "981\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction\n",
       "0        1415\n",
       "1        1877\n",
       "2        1544\n",
       "3        2389\n",
       "4        2031"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(n_components=30)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pca.fit(X_tr)\n",
    "pred = regr_lasso_stand_opt.predict(pca.transform(scaler.fit_transform(X_te)))\n",
    "pred = inv_label_transform(k,b,pred)\n",
    "print(pred.shape)\n",
    "pred_int = list(map(int, np.where(pred>0,pred,0)))\n",
    "print(max(np.array(pred_int)))\n",
    "print(min(np.array(pred_int)))\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df['Prediction'] = pred_int\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\n"
     ]
    }
   ],
   "source": [
    "print(max(pred_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('lasso_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': range(10, 100, 10)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[ 11.38736  11.61005 ...,  11.40978  11.69857], n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': range(10, 100, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_log_error', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start of nearest neighbors prediction\n",
    "import math\n",
    "from sklearn import neighbors\n",
    "from sklearn import model_selection\n",
    "\n",
    "regressor = neighbors.KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors':range(10,100,10) }\n",
    "print(param_grid)\n",
    "clf_knn_opt = model_selection.GridSearchCV(regressor,  param_grid=param_grid, cv=folds_regr,scoring='neg_mean_squared_log_error')\n",
    "clf_knn_opt.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 60}\n"
     ]
    }
   ],
   "source": [
    "print(clf_knn_opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "0.765300388074\n",
      "12.9522688025\n"
     ]
    }
   ],
   "source": [
    "def cross_validate(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions. \n",
    "    Use a scaler to scale the features to mean 0, standard deviation 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  Regressor instance; must have the following methods:\n",
    "        - fit(X, y) to train the regressor on the data X, y\n",
    "        - predict_proba(X) to apply the trained regressor to the data X and return predicted values\n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    #labels = np.array(labels)\n",
    "    n_classes = np.unique(labels).size\n",
    "   # print(labels.shape[0])\n",
    "    pred = np.zeros(labels.shape[0])\n",
    "    for tr, te in cv_folds:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        ytr =  labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        regressor.fit(Xtr, ytr)\n",
    "        prediction = regressor.predict(Xte)\n",
    "        pred[te] = prediction\n",
    "    return pred\n",
    "\n",
    "ypred_clf_knn_opt = cross_validate(X_tr,y_tr,clf_knn_opt.best_estimator_,folds_regr)\n",
    "print(ypred_clf_knn_opt.shape)\n",
    "print(metrics.mean_squared_log_error(inv_label_transform(k,b,y_tr),inv_label_transform(k,b,ypred_clf_knn_opt)))\n",
    "print(max(ypred_clf_knn_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 10}\n",
      "{'max_features': 20}\n",
      "{'max_features': 2}\n",
      "{'max_features': 2}\n",
      "{'max_features': 2}\n",
      "13.2871775073\n",
      "0.732215782379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nbt = ensemble.BaggingRegressor(n_estimators=100)\\nparam_grid = {'max_features':[7]}\\nregr_bt = model_selection.GridSearchCV(bt,param_grid=param_grid,scoring='neg_mean_squared_error')\\nypred_bt_opt = cross_validate_reg_optimize(X_tr,y_tr,regr_bt,folds_regr)\\nprint(max(ypred_bt_opt))\\nprint(metrics.mean_squared_log_error(y_tr,ypred_bt_opt))\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#START OF RANDOM FORESTS\n",
    "from sklearn import ensemble\n",
    "def cross_validate_reg_optimize(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  sklearn classifier object\n",
    "        Classifier instance; must have the following methods:\n",
    "        - fit(X, y) to train the classifier on the data X, y\n",
    "        - predict_proba(X) to apply the trained classifier to the data X and return probability estimates \n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    pred = np.zeros(labels.shape)\n",
    "    for tr, te in cv_folds:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        ytr =  labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        regressor.fit(Xtr, ytr)\n",
    "        print(regressor.best_params_)\n",
    "        prediction = regressor.best_estimator_.predict(Xte)\n",
    "        pred[te] = prediction\n",
    "    return pred\n",
    "\n",
    "rf = ensemble.RandomForestRegressor(n_estimators=200)\n",
    "param_grid = {'max_features':[2,4,6,8,10,12,14,16,18,20]}\n",
    "regr_rf = model_selection.GridSearchCV(rf,param_grid=param_grid,scoring='neg_mean_squared_log_error')\n",
    "ypred_rf_opt = cross_validate_reg_optimize(X_tr,y_tr,regr_rf,folds_regr)\n",
    "print(max(ypred_rf_opt))\n",
    "print(metrics.mean_squared_log_error(inv_label_transform(k,b,y_tr),inv_label_transform(k,b,ypred_rf_opt)))\n",
    "\"\"\"\n",
    "bt = ensemble.BaggingRegressor(n_estimators=100)\n",
    "param_grid = {'max_features':[7]}\n",
    "regr_bt = model_selection.GridSearchCV(bt,param_grid=param_grid,scoring='neg_mean_squared_error')\n",
    "ypred_bt_opt = cross_validate_reg_optimize(X_tr,y_tr,regr_bt,folds_regr)\n",
    "print(max(ypred_bt_opt))\n",
    "print(metrics.mean_squared_log_error(y_tr,ypred_bt_opt))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854182596665\n",
      "6781.46583104\n",
      "{'max_features': 2}\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(metrics.mean_squared_log_error(inv_label_transform(k,b,y_tr),inv_label_transform(k,b,ypred_rf_opt))))\n",
    "ypred_rf_opt_1 = inv_label_transform(k,b,ypred_rf_opt)\n",
    "print(max(ypred_rf_opt_1))\n",
    "print(regr_rf.best_params_)\n",
    "#print(np.sort(y_tr[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "5327\n",
      "861\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction\n",
       "0        1563\n",
       "1        2116\n",
       "2        1544\n",
       "3        2159\n",
       "4        2265"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "pred = regr_rf.predict(scaler.fit_transform(X_te))\n",
    "pred = inv_label_transform(k,b,pred)\n",
    "print(pred.shape)\n",
    "pred_int = list(map(int, np.where(pred>0,pred,0)))\n",
    "print(max(np.array(pred_int)))\n",
    "print(min(np.array(pred_int)))\n",
    "pred_rf = pd.DataFrame()\n",
    "pred_rf['Prediction'] = pred_int\n",
    "pred_rf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_rf.to_csv('rf_super.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(max(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x114acb198>]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4S8ikoP+PyqT2HUHhWjOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1154100f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log(0.1*np.sort(y_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
